{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf72d3b",
   "metadata": {},
   "source": [
    "# Lab 3: Extending Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db54406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d76f9",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea67566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
      "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
      "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
      "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
      "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
      "\n",
      "   Income  \n",
      "0     3.0  \n",
      "1     1.0  \n",
      "2     8.0  \n",
      "3     6.0  \n",
      "4     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Index(['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
      "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
      "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Diabetes_Dataset/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb247fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        NoDiabetes  PreDiabetes  Diabetes  HighBP  HighChol  CholCheck  BMI  \\\n",
      "0                1            0         0       1         1          1   40   \n",
      "1                1            0         0       0         0          0   25   \n",
      "2                1            0         0       1         1          1   28   \n",
      "3                1            0         0       1         0          1   27   \n",
      "4                1            0         0       1         1          1   24   \n",
      "...            ...          ...       ...     ...       ...        ...  ...   \n",
      "253675           1            0         0       1         1          1   45   \n",
      "253676           0            0         1       1         1          1   18   \n",
      "253677           1            0         0       0         0          1   28   \n",
      "253678           1            0         0       1         0          1   23   \n",
      "253679           0            0         1       1         1          1   25   \n",
      "\n",
      "        Smoker  Stroke  HeartDiseaseorAttack  ...  AnyHealthcare  NoDocbcCost  \\\n",
      "0            1       0                     0  ...              1            0   \n",
      "1            1       0                     0  ...              0            1   \n",
      "2            0       0                     0  ...              1            1   \n",
      "3            0       0                     0  ...              1            0   \n",
      "4            0       0                     0  ...              1            0   \n",
      "...        ...     ...                   ...  ...            ...          ...   \n",
      "253675       0       0                     0  ...              1            0   \n",
      "253676       0       0                     0  ...              1            0   \n",
      "253677       0       0                     0  ...              1            0   \n",
      "253678       0       0                     0  ...              1            0   \n",
      "253679       0       0                     1  ...              1            0   \n",
      "\n",
      "        GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  Income  \n",
      "0             5        18        15         1    0    9          4       3  \n",
      "1             3         0         0         0    0    7          6       1  \n",
      "2             5        30        30         1    0    9          4       8  \n",
      "3             2         0         0         0    0   11          3       6  \n",
      "4             2         3         0         0    0   11          5       4  \n",
      "...         ...       ...       ...       ...  ...  ...        ...     ...  \n",
      "253675        3         0         5         0    1    5          6       7  \n",
      "253676        4         0         0         1    0   11          2       4  \n",
      "253677        1         0         0         0    0    2          5       2  \n",
      "253678        3         0         0         0    1    7          5       1  \n",
      "253679        2         0         0         0    0    9          6       2  \n",
      "\n",
      "[253680 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating target features by modifying first column in original dataframe such that we have 3 features consisting of binary values for\n",
    "# no diabetes, prediabetes, and diabetes where 0 is False and 1 is True\n",
    "target_array = np.zeros((len(df),4))\n",
    "for i in range(len(df)):\n",
    "    target_array[i,0] = df['Diabetes_012'].values[i]\n",
    "for i in range(len(target_array)):\n",
    "    # no diabetes\n",
    "    if target_array[i,0] == 0:\n",
    "        target_array[i,1] = 1\n",
    "    # prediabetes\n",
    "    if target_array[i,0] == 1:\n",
    "        target_array[i,2] = 1\n",
    "    # diabetes\n",
    "    if target_array[i,0] == 2:\n",
    "        target_array[i,3] = 1\n",
    "\n",
    "# Adding new target columns to original dataframe\n",
    "target_columns = ['NoDiabetes', 'PreDiabetes', 'Diabetes']\n",
    "for i in range(target_array.shape[1]-1):\n",
    "    df.insert(i, target_columns[i], target_array[:,1:][:,i], True)\n",
    "df_target = df.drop('Diabetes_012', axis=1)\n",
    "\n",
    "columns = list(df_target.columns)\n",
    "for col in columns:\n",
    "    df_target[col] = df_target[col].astype(int)\n",
    "print(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2327f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['NoDiabetes', 'PreDiabetes', 'Diabetes']\n",
    "for col in targets:\n",
    "    columns.remove(col)\n",
    "    \n",
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_target, test_size=.20, random_state=42, shuffle=True)\n",
    "\n",
    "X_test  = test[columns].to_numpy()\n",
    "X_train = train[columns].to_numpy()\n",
    "y_test  = {}\n",
    "y_train = {}\n",
    "\n",
    "for col in targets:\n",
    "    y_test[col]  = test[col].to_numpy()\n",
    "    y_train[col] = train[col].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f871da1",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc57904",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d07fa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20, optimization='sd', regularization='none', C=0.001):\n",
    "        \n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.opt = optimization\n",
    "        self.reg = regularization\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, _add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if _add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) # return the actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20dc72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    # private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # creating ability to choose optimization technique\n",
    "    def _get_gradient(self,X,y):\n",
    "        \n",
    "        gradient = None\n",
    "        if self.opt == 'sd': gradient = self.steepest_descent\n",
    "        elif self.opt == 'sgd': gradient = self.stochastic_gradient_descent\n",
    "        elif self.opt == 'newton': gradient = self.newton\n",
    "        return gradient(X,y)\n",
    "    \n",
    "    def steepest_descent(self,X,y):\n",
    "    \n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    def stochastic_gradient_descent(self,X,y):\n",
    "        \n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    def newton(self,X,y):\n",
    "        \n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # regularization methods\n",
    "    def _get_reg_gradient(self):\n",
    "        \n",
    "        if self.reg == 'none':\n",
    "            return self.w_[1:]\n",
    "        elif self.reg == 'L1':\n",
    "            return np.sign(self.w_[1:])\n",
    "        elif self.reg == 'L2':\n",
    "            return -2 * self.w_[1:]\n",
    "        elif self.reg == 'L1_L2':\n",
    "            return -2 * self.w_[1:] + np.sign(self.w_[1:])    \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(int(self.iters)):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b9762",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2d16ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7fe7f8a64cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, eta, iterations=20, optimization='sd', regularization='none', C=0.001):\n",
    "        \n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.opt = optimization\n",
    "        self.reg = regularization\n",
    "        self.C = C\n",
    "        self.encodings = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        self.classifiers_ = []\n",
    "        for target in y.items():\n",
    "            blr = BinaryLogisticRegression(self.opt, self.eta, self.iters, self.reg, self.C )\n",
    "            blr.fit(X,target)\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # saving weights\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        \n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
    "    \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "lr = LogisticRegression('sd', 0.01, 100, 'ridge')\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "061e8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Testing Dataset:  0.15651608325449384  -  NoDiabetes\n",
      "Accuracy of Testing Dataset:  0.9813938820561338  -  PreDiabetes\n",
      "Accuracy of Testing Dataset:  0.8620900346893724  -  Diabetes\n"
     ]
    }
   ],
   "source": [
    "# Validating training dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression(optimization='sd',eta=0.9, regularization='none', iterations=10, C=0.001)\n",
    "for col in targets:\n",
    "    lr.fit(X_train, y_train)\n",
    "    yhat = lr.predict(X_test)\n",
    "    print(\"Accuracy of Testing Dataset: \", accuracy_score(y_test[col],yhat), \" - \", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21eff765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Testing Dataset:  0.15651608325449384  -  NoDiabetes\n",
      "Accuracy of Testing Dataset:  0.9813938820561338  -  PreDiabetes\n",
      "Accuracy of Testing Dataset:  0.8620900346893724  -  Diabetes\n"
     ]
    }
   ],
   "source": [
    "# Increasing # of iterations\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression(optimization='sd',eta=0.9, regularization='none', iterations=10, C=0.01)\n",
    "for col in targets:\n",
    "    lr.fit(X_train, y_train)\n",
    "    yhat = lr.predict(X_test)\n",
    "    print(\"Accuracy of Testing Dataset: \", accuracy_score(y_test[col],yhat), \" - \", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37020124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
