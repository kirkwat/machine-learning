{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Six: CNNs\n",
    "\n",
    "Team: Miro Ronac, Kirk Watson, Brandon Vincitore\n",
    "\n",
    "Dataset Source: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation\n",
    "\n",
    "Load in images for dataset similar to Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1731 total images with 10000 features\n",
      "Number of files: 1731\n",
      "Number of normal images: 1341 , Number of pneumonia images: 390\n"
     ]
    }
   ],
   "source": [
    "#file paths were chosen to have reasonably sized dataset\n",
    "normal_dir = \"chest_xray/train/NORMAL/\"\n",
    "pneumonia_dir = \"chest_xray/test/PNEUMONIA/\"\n",
    "\n",
    "data = []\n",
    "classes = []\n",
    "h, w = 100, 100\n",
    "\n",
    "#load normal images\n",
    "normal_count=0\n",
    "for images in os.listdir(normal_dir):\n",
    "    #create image, resize to 100x100\n",
    "    image = Image.open(normal_dir + images)\n",
    "    image = image.resize((h,w))\n",
    "    #convert image to numpy array and flatten\n",
    "    data_i = asarray(image)\n",
    "    feature_i = data_i.flatten()\n",
    "    #add image to list of images\n",
    "    data.append(feature_i)\n",
    "    #store as false (not pneumonia)\n",
    "    classes.append(0)\n",
    "    normal_count+=1\n",
    "    \n",
    "#load pneumonia images\n",
    "pneumonia_count=0\n",
    "for images in os.listdir(pneumonia_dir):\n",
    "    #create image, resize to 100x100\n",
    "    image = Image.open(pneumonia_dir + images)\n",
    "    image = image.resize((h,w))\n",
    "    #convert image to numpy array and flatten\n",
    "    data_i = asarray(image)\n",
    "    feature_i = data_i.flatten()\n",
    "    #add image to list of images\n",
    "    data.append(feature_i)\n",
    "    #store as true (pneumonia)\n",
    "    classes.append(1)\n",
    "    pneumonia_count+=1\n",
    "    \n",
    "data = np.asarray(data)\n",
    "print(data.shape[0], 'total images with', data.shape[1], 'features')\n",
    "print('Number of files:', len(classes))\n",
    "print('Number of normal images:', normal_count, ', Number of pneumonia images:',pneumonia_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "\n",
    "We chose to use the F1-score metric to account for the false negatives (recall) and false positives (precision) when evaulating our unbalanced unbalanced dataset. In the world of medicine and diagnostics, both false negatives and false positives are extremely important when evaluating a patient. We don't want to wrongly diagnose a patient with pneumonia, and we wouldn't want to wrongly diagnose a patient's lungs as healthy. With the F1-score, we have a better metric to minimize both false ocurrences. Additionally, our dataset is unbalanced in favor of normal lung images. The F1-score suits unbalanced datasets because it is calculated as a harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# F1-score is no longer supported in keras so we must make a F1-score function\n",
    "# From https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
    "\n",
    "def f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data into training and testing\n",
    "\n",
    "To divide our data into training and testing, we will use Stratified K-fold cross validation. We chose this method because we need to account for the imbalance of normal images and pneumonia images. A stratified split will create folds with balanced occurences of normal and pneumonia images. Using a K-fold split is beneficial for our small dataset because it will better assist our model with generalization. A K-fold split will help reduce variance and allow the model to fit with each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = data\n",
    "y = np.asarray(classes)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
