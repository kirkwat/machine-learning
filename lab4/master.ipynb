{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Four: The Multi-Layer Perceptron\n",
    "\n",
    "Team: Miro Ronac, Kirk Watson, Brandon Vincitore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load, Split, and Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: 74001\n",
      "Size after removing missing data: 72718\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load the data into memory and save it to a pandas data frame\n",
    "df = pd.read_csv('acs2017_census_tract_data.csv')\n",
    "print('Dataset Size:', df.shape[0])\n",
    "#Remove any observations that having missing data\n",
    "df.dropna(inplace=True)\n",
    "print('Size after removing missing data:', df.shape[0])\n",
    "#Encode any string data as integers\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "    \n",
    "#TODO - decide whether or not to remove the county variable. examples removed \"ChildPoverty\", \"TractId\", \"County\"\n",
    "#TODO - finish removing stuff\n",
    "\n",
    "#set y as child poverty rate and remove unneeded columns\n",
    "y = df.ChildPoverty\n",
    "X = df.drop([\"ChildPoverty\", \"TractId\", \"County\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: (58174, 34)\n",
      "Testing Set Size: (14544, 34)\n",
      "Bin Quartile Ranges: [  0.    6.2  16.4  31.7 100. ]\n",
      "Training Bin Class Sizes: [14596 14580 14476 14522]\n",
      "Test Bin Class Sizes: [3633 3753 3599 3559]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#set y as child poverty rate\n",
    "y = df.ChildPoverty\n",
    "#Split the dataset into 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(),\n",
    "                                                    test_size=.20, random_state=42)\n",
    "print(\"Training Set Size:\",X_train.shape)\n",
    "print(\"Testing Set Size:\",X_test.shape)\n",
    "\n",
    "#create 4 classification levels\n",
    "#Balance the dataset so that about the same number of instances are within each class\n",
    "y_train, bins = pd.qcut(y_train, q=4, labels=[0,1,2,3], retbins=True)\n",
    "#Use bins to make classifications for testing set\n",
    "y_test = pd.cut(y_test, bins, labels=[0,1,2,3], include_lowest=True)\n",
    "\n",
    "print(\"Bin Quartile Ranges:\",bins)\n",
    "print(\"Training Bin Class Sizes:\",np.bincount(y_train))\n",
    "print(\"Test Bin Class Sizes:\",np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You have the option of keeping the \"county\" variable or removing it. Be sure to discuss why you decided to keep/remove this variable.**\n",
    "\n",
    "TODO - Explain why we decided to remove the county variable\n",
    "\n",
    "**Choose a method for balancing the dataset and explain your reasoning for selecting this method.**\n",
    "\n",
    "To balance the dataset, we identified 4 quartile ranges using a quantile-based discretization function from Pandas. This function is able to create equal-sized buckets of observations based on the \"ChildPoverty\" feature. This method utilized to balance the dataset creates an accurate representation of the entire dataset which is necessary when training our classifier.\n",
    "\n",
    "**Should balancing of the dataset be done for both the training and testing set? Explain.**\n",
    "\n",
    "In most cases, the testing set should not be balanced while the training set should be balanced. The training set should be balanced to avoid creating biases to over-represented or under-represented classes when training the classifier. Not balancing the testing set allows for a true performance evaluation of the classifier. Testing sets represent untampered data that the classifier might experience in the real world. A balanced testing set is unrealistic and can introduce bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
