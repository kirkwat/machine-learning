{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299ba369",
   "metadata": {},
   "source": [
    "# Lab 4: The Multi-Layer Perceptron\n",
    "\n",
    "## 1. Load Dataset: Modify dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c988125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: 74001\n",
      "Size after removing missing data: 72718\n",
      "We need to encode these columns as integers:  State County\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data into memory and save it to a pandas data frame\n",
    "df = pd.read_csv('Census_Data/acs2017_census_tract_data.csv')\n",
    "print('Dataset Size:', df.shape[0])\n",
    "# Remove any observations that having missing data\n",
    "df.dropna(inplace=True)\n",
    "print('Size after removing missing data:', df.shape[0])\n",
    "print('We need to encode these columns as integers: ', df.select_dtypes(include='object').columns[0],df.select_dtypes(include='object').columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c6645a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  TotalPop   Men  Women  Hispanic  White  Black  Native  Asian  \\\n",
       "0      0      1845   899    946       2.4   86.3    5.2     0.0    1.2   \n",
       "1      0      2172  1167   1005       1.1   41.6   54.5     0.0    1.0   \n",
       "2      0      3385  1533   1852       8.0   61.4   26.5     0.6    0.7   \n",
       "3      0      4267  2001   2266       9.6   80.3    7.1     0.5    0.2   \n",
       "4      0      9965  5054   4911       0.9   77.5   16.4     0.0    3.1   \n",
       "\n",
       "   Pacific  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
       "0      0.0  ...   0.5          0.0         2.1         24.5       881   \n",
       "1      0.0  ...   0.0          0.5         0.0         22.2       852   \n",
       "2      0.4  ...   1.0          0.8         1.5         23.1      1482   \n",
       "3      0.0  ...   1.5          2.9         2.1         25.9      1849   \n",
       "4      0.0  ...   0.8          0.3         0.7         21.0      4787   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         74.2        21.2           4.5         0.0           4.6  \n",
       "1         75.9        15.0           9.0         0.0           3.4  \n",
       "2         73.3        21.1           4.8         0.7           4.7  \n",
       "3         75.8        19.7           4.5         0.0           6.1  \n",
       "4         71.4        24.1           4.5         0.0           2.3  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode any string data as integers\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# Set y as child poverty rate and remove unneeded columns\n",
    "y = df.ChildPoverty\n",
    "X = df.drop([\"ChildPoverty\", \"TractId\", \"County\"], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331922a",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a3b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: (58174, 34)\n",
      "Testing Set Size: (14544, 34)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the dataset into 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(),\n",
    "                                                    test_size=.20, random_state=42)\n",
    "print(\"Training Set Size:\",X_train.shape)\n",
    "print(\"Testing Set Size:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063aa39",
   "metadata": {},
   "source": [
    "## Balance Dataset: Quantize child poverty rate into 4 classes and balance dataset by equally distributing across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e242ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Quartile Ranges: [  0.    6.2  16.4  31.7 100. ]\n"
     ]
    }
   ],
   "source": [
    "# Balance the dataset so that about the same number of instances are within each class\n",
    "y_train, bins = pd.qcut(y_train, q=4, labels=[0,1,2,3], retbins=True) # constructing 4 classification levels\n",
    "print(\"Bin Quartile Ranges:\",bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff4095",
   "metadata": {},
   "source": [
    "We balanced the dataset above by identifying 4 quartile ranges using a quantile-based discretization function from Pandas. This function is able to create equal-sized buckets of observations based on the \"ChildPoverty\" feature. This method utilized to balance the dataset creates an accurate representation of the entire dataset which is necessary when training our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b268e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bin Class Sizes: [14596 14580 14476 14522]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we can see that we did a good job of balancing our quantization for the training set.\n"
     ]
    }
   ],
   "source": [
    "# Output number of instances and plot\n",
    "print(\"Training Bin Class Sizes:\",np.bincount(y_train))\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.pie(np.bincount(y_train),\n",
    "        labels=['Very low', 'Moderate', 'High', 'Very high'],\n",
    "        autopct='%.2f%%')\n",
    "plt.show()\n",
    "print('Here we can see that we did a good job of balancing our quantization for the training set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7ccd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Bin Class Sizes: [3633 3753 3599 3559]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we can see that our test set is also balanced relatively well.\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.cut(y_test, bins, labels=[0,1,2,3], include_lowest=True)\n",
    "print(\"Test Bin Class Sizes:\",np.bincount(y_test))\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.pie(np.bincount(y_test),\n",
    "        labels=['Very low', 'Moderate', 'High', 'Very high'],\n",
    "        autopct='%.2f%%')\n",
    "plt.show()\n",
    "print('Here we can see that our test set is also balanced relatively well.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9cb48",
   "metadata": {},
   "source": [
    "In most cases, the testing set should not be balanced while the training set should be balanced. The training set should be balanced to avoid creating biases to over-represented or under-represented classes when training the classifier. Not balancing the testing set allows for a true performance evaluation of the classifier. Testing sets represent untampered data that the classifier might experience in the real world. A balanced testing set is unrealistic and can introduce bias. We will have to work with a balanced test dataset because we need to be able to classify the test dataset within the same child poverty rate ranges as our training set (i.e., the bounds we set on each poverty rate needs to remain the same throughout our model to avoid misclassification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f4089",
   "metadata": {},
   "source": [
    "#### You have the option of keeping the \"county\" variable or removing it. Be sure to discuss why you decided to keep/remove this variable.\n",
    "\n",
    "TODO - Explain why we decided to remove the county variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127d6de",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing\n",
    "###### Starting with simple base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2e8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "#Original Author: Sebastian Raschka\n",
    "\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        \n",
    "# Don't one-hot encode yet        \n",
    "#     @staticmethod\n",
    "#     def _encode_labels(y):\n",
    "#         \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "#         onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "#         return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_) # reshape to be W\n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden)\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2, b1, b2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs \n",
    "\n",
    "        \"\"\"\n",
    "        A1 = X.T\n",
    "        Z1 = W1 @ A1 + b1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        Z2 = W2 @ A2 + b2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2, self.b1, self.b2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9368a",
   "metadata": {},
   "source": [
    "###### Add mini-batch to vectorized TLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08af8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "#         Y_enc = self._encode_labels(y) # not yet\n",
    "        Y_enc = y.copy() # change this back once we decide to one hot encode\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2, self.b1, self.b2 = self._initialize_weights()\n",
    "\n",
    "        rho_W1_prev = np.zeros(self.W1.shape)\n",
    "        rho_W2_prev = np.zeros(self.W2.shape)\n",
    "        rho_b1_prev = np.zeros(self.b1.shape)\n",
    "        rho_b2_prev = np.zeros(self.b2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        # get starting acc\n",
    "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "        # keep track of validation, if given\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "            self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            # \\frac{\\eta}{1+\\epsilon\\cdot k}\n",
    "            eta = self.eta / (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                gradW1, gradW2, gradb1, gradb2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                # momentum calculations\n",
    "                rho_W1, rho_W2 = eta * gradW1, eta * gradW2\n",
    "                rho_b1, rho_b2 = eta * gradb1, eta * gradb2\n",
    "                self.W1 -= (rho_W1 + (self.alpha * rho_W1_prev)) # update with momentum\n",
    "                self.W2 -= (rho_W2 + (self.alpha * rho_W2_prev)) # update with momentum\n",
    "                self.b1 -= (rho_b1 + (self.alpha * rho_b1_prev))\n",
    "                self.b2 -= (rho_b2 + (self.alpha * rho_b2_prev))\n",
    "                rho_W1_prev, rho_W2_prev = rho_W1, rho_W2\n",
    "                rho_b1_prev, rho_b2_prev = rho_b1, rho_b2\n",
    "                \n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ae53a",
   "metadata": {},
   "source": [
    "###### Now implement cross entropy by updating cost function  and change V2 in gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2eb8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = (A3-Y_enc) # <- this is only line that changed\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958ba0b",
   "metadata": {},
   "source": [
    "###### Last step is proper utilization of Glorot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1fc8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPBetterInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_))\n",
    "\n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden)) \n",
    "        \n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613be623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def print_result(nn,X_train,y_train,X_test,y_test,title=\"\",color=\"red\"):\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(title,\":\")\n",
    "    yhat = nn.predict(X_train)\n",
    "    print('Resubstitution acc:',accuracy_score(y_train,yhat))\n",
    "    \n",
    "    yhat = nn.predict(X_test)\n",
    "    print('Validation acc:',accuracy_score(y_test,yhat))\n",
    "    \n",
    "    if hasattr(nn,'val_score_'):\n",
    "        plt.plot(range(len(nn.val_score_)), nn.val_score_, color=color,label=title)\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "    else:\n",
    "        plt.plot(range(len(nn.score_)), nn.score_, color=color,label=title)\n",
    "        plt.ylabel('Resub Accuracy')\n",
    "        \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = { 'n_hidden':30, \n",
    "         'C':0.1, 'epochs':10, 'eta':0.001, \n",
    "         'alpha':0.001, 'decrease_const':1e-5, 'minibatches':50,\n",
    "         'shuffle':True,'random_state':1}\n",
    "\n",
    "nn_better = TLPBetterInitial(**vals)\n",
    "\n",
    "%time nn_better.fit(X_train, y_train, print_progress=1, XY_test=(X_test, y_test))\n",
    "\n",
    "print_result(nn_better,X_train,y_train,X_test,y_test,title=\"Glorot Initial\",color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966689a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
